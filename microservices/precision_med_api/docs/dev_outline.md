# Genomic Carrier Screening API - Development Status

## üìã Current Status Summary

### ‚úÖ **Completed Phases**
- **Phase 1**: Foundation (Data models, config, file discovery)
- **Phase 2**: Core Processing (Merge-based harmonization, extraction, coordination)
- **Phase 3A**: ProcessPool Parallelization (True concurrent processing)
- **Phase 3B**: Data Quality & Organization (Correct allele counting, sample ID normalization, column organization)
- **Phase 3C**: Streamlit Viewer (Interactive web interface for result exploration)
- **Phase 3D**: Critical Bug Fixes (Multiple probe detection, sample counting accuracy)
- **Phase 4**: Postprocessing (Advanced analysis on extracted data)
- **Phase 4A**: Probe Selection Method (NBA probe quality analysis and selection against WGS ground truth)

### üéØ **Current Focus: Phase 4 Postprocessing** ‚úÖ **PHASE 4A COMPLETED**
- ‚úÖ **Phase 3 Core Pipeline**: Multiple probe detection, sample counting, enhanced Streamlit viewer
- ‚úÖ **Phase 4A Postprocessing**: Probe selection method with NBA/WGS quality validation
- **Phase 4B (Next)**: Variant Subset Preparation (per-locus metrics, cross-dataset measures)
- **Phase 5 (Future)**: Frontend Development (API endpoints, web interface)

---

## üèóÔ∏è Architecture Overview

### **Core Challenge**
Process ~400 pathogenic SNPs across 254 PLINK files from three data sources:
- **NBA**: 11 files (split by ancestry)
- **WGS**: 1 file (consolidated)  
- **IMPUTED**: 242 files (11 ancestries √ó 22 chromosomes)

### **Technical Solution**
- **Multiple Probe Detection**: Fixed NBA variants with multiple probes at same position being lost during deduplication
- **Correct Allele Counting**: Fixed to count pathogenic alleles instead of reference alleles
- **Advanced Genotype Transformation**: Proper handling of all harmonization scenarios with genotype flipping
- **Sample ID Normalization**: Consistent sample IDs across data types (removes '0_' prefixes, fixes WGS duplicates)
- **Accurate Sample Counting**: Fixed pipeline summary to report correct sample counts
- **Merge-Based Harmonization**: Real-time PVAR/SNP list merging with allele comparison
- **ProcessPool Parallelization**: True concurrent processing across all files
- **Memory-Efficient Processing**: Stream processing staying under 8GB RAM
- **Enhanced Streamlit Viewer**: Interactive web interface with multiple probes analysis and debug mode
- **Column Organization**: Metadata columns first, then sorted sample columns

---

## üöÄ Recent Major Achievements

### **Phase 3B: Data Quality & Organization** ‚úÖ

**Critical Allele Counting Fix** ‚úÖ
- **Problem**: Pipeline was counting reference alleles instead of pathogenic alleles
- **Solution**: Implemented proper allele assignment and genotype transformation
- **Impact**: Genotype values now correctly represent pathogenic allele counts (0=none, 1=het carrier, 2=hom carrier)
- **Implementation**: Enhanced `_harmonize_extracted_genotypes()` with scenario-specific handling

**Sample ID Normalization** ‚úÖ  
- **WGS Duplicates**: `SAMPLE_001234_SAMPLE_001234` ‚Üí `SAMPLE_001234`
- **NBA/IMPUTED Prefixes**: `0_SAMPLE_001234` ‚Üí `SAMPLE_001234`
- **Result**: Consistent sample IDs across all data types for easy data integration
- **Implementation**: Added `_normalize_sample_id()` method with duplicate detection

**Column Organization** ‚úÖ
- **Metadata First**: 15 metadata columns in defined order, then sorted sample columns
- **Duplicate Handling**: Prevents column name conflicts after normalization
- **Implementation**: Enhanced `_reorder_dataframe_columns()` method in coordinator.py

**Code Quality Improvements** ‚úÖ
- **Test Suite Streamlining**: Reduced transformer.py by 83% (348‚Üí58 lines), removed 11 unused functions
- **Redundancy Analysis**: Identified 9 duplicate columns between parquet and variant_summary files
- **Performance**: 3 tests passing, zero warnings

### **Phase 3C: Streamlit Viewer** ‚úÖ **COMPLETED**

**Interactive Web Interface** ‚úÖ
- **üìä Overview Tab**: Pipeline summary, sample counts, file information
- **üß¨ Variant Browser**: Filter variants by harmonization action, chromosome, ancestry
- **üìà Statistics Tab**: Visualizations of harmonization distributions and variant counts  
- **üíæ File Downloads**: Direct access to processed parquet and summary files

**Key Features** ‚úÖ
- **Real-time Data Loading**: Direct GCS mount access without file uploads
- **Redundancy Cleanup**: Streamlined to show only relevant columns (removed COUNTED/ALT duplicates)
- **User Education**: Clear explanation that genotypes represent pathogenic allele counts

### **Phase 3D: Critical Bug Fixes** ‚úÖ **COMPLETED**

**Multiple Probe Detection Fix** ‚úÖ **CRITICAL**
- **Problem**: NBA variants with multiple probes at the same genomic position were being lost during processing
- **Root Cause**: SNP ID mismatch between harmonization (coordinate-based) and plan creation (SNP names)
- **Solution**: 
  - Fixed harmonization to use `snp_name` instead of `variant_id` in records
  - Updated coordinator to pass `snp_name` as `snp_list_ids` 
  - Modified deduplication to include `variant_id` to preserve different probes
- **Impact**: 77 SNPs now correctly show multiple probes (316 variants vs 218 previously)
- **Implementation**: Updated `app/processing/harmonizer.py` and `app/processing/coordinator.py`

**Sample Counting Fix** ‚úÖ  
- **Problem**: Pipeline summary reported "Total samples: 0" instead of actual count
- **Root Cause**: `source_file` column missing from metadata list, sample aggregation not working
- **Solution**: 
  - Added `source_file` to `_get_sample_columns()` metadata list
  - Implemented proper sample count aggregation in `export_pipeline_results()`
- **Impact**: Accurate reporting of 1,215 samples in pipeline summaries
- **Implementation**: Updated `app/processing/output.py` and `app/processing/coordinator.py`

**Enhanced Streamlit Viewer** ‚úÖ
- **Multiple Probes Analysis**: New section showing SNPs with multiple probes detected
- **Debug Mode**: Optional job selection with `./run_streamlit.sh --debug` for development
- **Deprecation Fix**: Updated `use_container_width` to `width='stretch'` 
- **Production/Debug Split**: Clean interface for users, full access for developers

### **Phase 4: Postprocessing** ‚úÖ **PHASE 4A COMPLETED**

### **Phase 4A: Probe Selection Method** ‚úÖ **COMPLETED**

**NBA Probe Quality Analysis** ‚úÖ
- **Objective**: Validate NBA probe performance against WGS ground truth data for optimal probe selection
- **Problem**: Multiple NBA probes exist for the same genomic position with varying quality/accuracy
- **Solution**: Dual-metric analysis system comparing NBA probes to WGS data as ground truth

**Implementation Features** ‚úÖ
- **Automatic Detection**: Identifies mutations with multiple NBA probes via `snp_list_id` grouping
- **Dual Validation Approaches**:
  - **Diagnostic Classification**: Treats carrier detection as binary classification (sensitivity/specificity focus)
  - **Genotype Concordance**: Exact genotype-level agreement analysis (0/1/2 comparison with transition matrix)
- **Consensus Recommendations**: Combines both approaches with confidence scoring and disagreement analysis
- **Quality Thresholds**: Configurable sensitivity (80%), specificity (95%), and concordance (90%) thresholds

**Key Components** ‚úÖ
- **ProbeSelector** (`app/processing/probe_selector.py`): Core analysis engine with diagnostic/concordance metrics
- **ProbeRecommendationEngine** (`app/processing/probe_recommender.py`): Strategy-based probe selection with consensus analysis
- **Integration**: Seamless integration with pipeline via `--enable-probe-selection` (default: enabled)
- **Output**: Comprehensive JSON reports with per-mutation analysis and methodology comparison

**Clinical Impact** ‚úÖ
- **Evidence-Based Selection**: Quantitative metrics support optimal probe choices for carrier screening
- **Quality Assurance**: Identifies poor-performing probes that may need exclusion from clinical analysis
- **Methodology Validation**: Agreement analysis between diagnostic and concordance approaches
- **Precision Medicine**: Improves diagnostic accuracy by selecting highest-quality probes

**Usage** ‚úÖ
```bash
# Automatic (default behavior)
python run_carriers_pipeline.py

# On existing results
python run_carriers_pipeline.py --skip-extraction --enable-probe-selection

# Explicit control
python run_carriers_pipeline.py --no-probe-selection  # disable
```

**Output Files** ‚úÖ
- `{job_name}_probe_selection.json`: Comprehensive probe analysis report with recommendations

---

## üéØ Next Phases: Advanced Analysis & Optimization

### **Phase 4B: Variant Subset Preparation** üîÑ **NEXT**
**Objective**: Prepare variant subsets with comprehensive metrics and cross-dataset analysis

**Planned Features**:
- **Per-Locus Metrics**: Variant-level statistics across all datasets (allele frequencies, carrier counts, quality scores)
- **Cross-Dataset Measures**: Compare variant detection and quality across NBA/WGS/IMPUTED sources
- **Population Stratification**: Ancestry-specific variant analysis and carrier frequency calculations
- **Quality Control Metrics**: Hardy-Weinberg equilibrium testing, call rate analysis, genotype concordance
- **Variant Annotation**: Integration of clinical significance, gene context, and pathogenicity scores
- **Subset Generation**: Create filtered variant sets based on quality thresholds and clinical relevance

### **Phase 5: Frontend Development** üéØ **FUTURE**
**Objective**: Build production-ready API and web interface for genomic analysis

**Phase 5A: API Development** üîÑ **PLANNED**
- **FastAPI Endpoints**: RESTful API for variant querying, analysis submission, and result retrieval
- **Authentication**: User management and secure access to genomic data
- **Background Processing**: Celery + Redis for long-running analysis jobs
- **Result Caching**: Optimized storage and retrieval of analysis results

**Phase 5B: Web Interface** üîÑ **PLANNED**
- **Interactive Dashboard**: Advanced web UI replacing Streamlit prototype
- **Variant Explorer**: Production-grade variant browsing with filtering and visualization
- **Analysis Workflow**: Guided interface for carrier screening and variant subset creation
- **Result Visualization**: Advanced charts, plots, and statistical summaries

---

## üìä Performance Targets

### **Current Performance** ‚úÖ
| Metric | Target | Status |
|--------|--------|---------|
| Single NBA File | <30s | ‚úÖ 18.5s |
| Memory Usage | <8GB | ‚úÖ Validated |
| ProcessPool Architecture | True parallelism | ‚úÖ Complete |
| Data Quality | Correct allele counting | ‚úÖ Fixed |
| Sample ID Consistency | Normalized across data types | ‚úÖ Complete |
| Test Coverage | Streamlined essential tests | ‚úÖ 3 tests passing |

### **Data Quality Achievements** ‚úÖ
| Metric | Target | Status |
|--------|--------|---------|
| Allele Counting | Pathogenic alleles counted | ‚úÖ Fixed |
| Sample ID Format | Consistent across NBA/WGS/IMPUTED | ‚úÖ Normalized |
| Column Organization | Metadata first, sorted samples | ‚úÖ Complete |
| Code Redundancy | Eliminate unused functions | ‚úÖ 83% reduction |
| Streamlit Interface | Interactive result exploration | ‚úÖ Complete |

### **Next Targets** üéØ
| Metric | Target | Status |
|--------|--------|---------|
| File Redundancy | Eliminate variant_summary.csv | üîÑ Proposed |
| Storage Optimization | 25% reduction via consolidation | üîÑ Next |
| Enhanced Carrier Analysis | Population-level statistics | üîÑ Next |

---

## üõ†Ô∏è Technology Stack

### **Core Technologies**
- **Backend**: FastAPI, Pydantic v2
- **Processing**: pandas, numpy, ProcessPoolExecutor
- **Genomics**: pgenlib (PLINK file processing)
- **Storage**: Parquet files with Snappy compression
- **Testing**: pytest (31 tests, zero warnings)

### **File Paths**
```
Input:  ~/gcs_mounts/gp2tier2_vwb/release10/
Output: ~/gcs_mounts/genotools_server/precision_med/results/
```

### **Development Setup**
```bash
# Always activate virtual environment
source .venv/bin/activate

# Run streamlined tests
python -m pytest tests/ -v  # 3 tests, zero warnings

# Test pipelines with real data
python test_nba_pipeline.py        # NBA test
python test_imputed_pipeline.py    # IMPUTED test

# Run full pipeline
python run_carriers_pipeline.py --job-name my_analysis

# Skip extraction for rapid postprocessing development
python run_carriers_pipeline.py --job-name my_analysis --skip-extraction

# Launch Streamlit viewer
streamlit run streamlit_viewer.py
# Or use convenience script (production mode)
./run_streamlit.sh
# Debug mode with job selection
./run_streamlit.sh --debug
```

### **Key Files Updated**
```
run_carriers_pipeline.py         # Added --skip-extraction, --enable-probe-selection flags
app/processing/harmonizer.py       # Fixed multiple probe detection with SNP name mapping
app/processing/coordinator.py      # Fixed sample counting, deduplication, probe selection integration
app/processing/output.py           # Added source_file to metadata columns
app/processing/extractor.py        # Fixed allele counting & genotype transformation
app/processing/probe_selector.py   # NEW: NBA probe quality analysis against WGS ground truth
app/processing/probe_recommender.py # NEW: Probe selection recommendations with consensus analysis
app/models/probe_validation.py     # NEW: Probe analysis data models and metrics
streamlit_viewer.py               # Enhanced with multiple probes analysis & debug mode
run_streamlit.sh                  # Added debug mode support
tests/test_transformer.py          # Streamlined to essential tests only
README.md                         # Updated with latest features and fixes
docs/dev_outline.md              # Updated development status
```

---

## üéØ Immediate Next Actions

### **Phase 4B: Variant Subset Preparation** (Immediate Priority)
1. **Per-Locus Statistics**: Calculate variant-level metrics (allele frequencies, carrier counts, call rates) across all datasets
2. **Cross-Dataset Quality Comparison**: Compare variant detection quality and concordance across NBA/WGS/IMPUTED sources
3. **Population Stratification**: Generate ancestry-specific variant analysis and carrier frequency calculations
4. **Quality Control Implementation**: Hardy-Weinberg equilibrium testing, genotype concordance, and filtering thresholds
5. **Variant Annotation Integration**: Add clinical significance, gene context, and pathogenicity metadata
6. **Subset Generation Tools**: Create filtered variant sets based on quality and clinical relevance criteria

### **Phase 5: Frontend Development** (Future Priority)
7. **API Endpoints**: Develop FastAPI endpoints for variant querying and analysis submission
8. **Web Interface**: Build production-grade dashboard replacing Streamlit prototype
9. **Authentication & Security**: Implement user management and secure genomic data access
10. **Background Processing**: Set up Celery + Redis for long-running analysis workflows

---

## üìà Success Metrics

### **Technical Metrics**
- ‚úÖ ProcessPool implementation (Component 7A)
- ‚úÖ Cross-DataType combination (Component 7)
- ‚úÖ **Multiple probe detection fix** (Critical bug preventing variant loss)
- ‚úÖ **Sample counting accuracy** (Fixed "Total samples: 0" reporting)
- ‚úÖ Correct allele counting fix (Critical data quality issue)
- ‚úÖ Sample ID normalization across data types
- ‚úÖ Column organization (metadata first, sorted samples)
- ‚úÖ Enhanced Streamlit viewer with debug mode and multiple probes analysis
- ‚úÖ **Probe Selection Method** (NBA probe quality validation against WGS ground truth)
- ‚úÖ Zero deprecation warnings (Streamlit and Pydantic v2)
- ‚úÖ Streamlined test suite (3 essential tests)
- üéØ File redundancy elimination
- üéØ Variant subset preparation with per-locus metrics and cross-dataset analysis

### **Quality Metrics**
- ‚úÖ Process isolation and error handling
- ‚úÖ Original allele transparency with harmonization tracking
- ‚úÖ IMPUTED file format support
- ‚úÖ **Enhanced deduplication logic** preserving multiple probes per SNP
- ‚úÖ **Critical Fix**: Pathogenic allele counting instead of reference alleles
- ‚úÖ **Complete data capture**: 77 SNPs with multiple probes (316 vs 218 variants)
- ‚úÖ **Accurate sample reporting**: 1,215 samples correctly counted
- ‚úÖ Consistent sample ID format across NBA/WGS/IMPUTED data types
- ‚úÖ User-friendly Streamlit interface with multiple probes analysis
- ‚úÖ **Production/Debug interface split** for optimal user experience
- ‚úÖ **Probe Quality Validation** with dual-metric analysis (diagnostic + concordance)
- ‚úÖ **Evidence-Based Probe Selection** with consensus recommendations and confidence scoring
- üéØ Storage optimization (25% reduction via consolidation)
- üéØ Per-locus metrics and cross-dataset quality measures

### **Impact Assessment**
The recent critical bug fixes and probe selection implementation represent a **major milestone** in pipeline development:
- **Data Completeness**: Fixed multiple probe detection ensuring 77 SNPs show all their probes (98 additional variants recovered)
- **Accuracy**: Pipeline summaries now correctly report 1,215 samples instead of misleading "0"
- **Correctness**: Fixed fundamental allele counting issue affecting all downstream analysis
- **Consistency**: Normalized sample IDs enable seamless cross-data-type integration
- **Usability**: Enhanced Streamlit interface with multiple probes analysis and production/debug modes
- **Maintainability**: Streamlined codebase with 83% reduction in unused code
- **Clinical Quality**: Evidence-based probe selection with WGS ground truth validation ensures optimal diagnostic accuracy
- **Methodology Validation**: Dual-metric analysis (diagnostic + concordance) provides comprehensive probe quality assessment

This comprehensive update ensures the pipeline now captures **all available genomic data**, produces **scientifically accurate** carrier frequency data, and provides **evidence-based probe selection** ready for population genetics analysis and clinical interpretation.