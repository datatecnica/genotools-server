# Precision Medicine API - Architecture & Code Documentation

## ðŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE ENTRY POINT                         â”‚
â”‚  run_carriers_pipeline.py â†’ ExtractionCoordinator               â”‚ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COORDINATION LAYER                           â”‚
â”‚  app/processing/coordinator.py                                  â”‚
â”‚  â€¢ ExtractionCoordinator (main orchestrator)                    â”‚
â”‚  â€¢ ProcessPool management & parallel execution                  â”‚
â”‚  â€¢ Multi-source data integration                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                
                            â–¼                
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EXTRACTION    â”‚ â”‚   HARMONIZATION   â”‚ â”‚   TRANSFORMATION  â”‚
â”‚                 â”‚ â”‚                   â”‚ â”‚                   â”‚
â”‚VariantExtractor â”‚ â”‚HarmonizationEngineâ”‚ â”‚GenotypeTransformerâ”‚
â”‚ â€¢ PLINK2 calls  â”‚ â”‚ â€¢ Allele compare  â”‚ â”‚ â€¢ Swap genotypes  â”‚
â”‚ â€¢ File reading  â”‚ â”‚ â€¢ Strand flips    â”‚ â”‚ â€¢ Validation      â”‚
â”‚ â€¢ Simulation    â”‚ â”‚ â€¢ Real-time       â”‚ â”‚ â€¢ QC metrics      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                       
                            â–¼                       
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT LAYER                                 â”‚
â”‚  app/processing/output.py                                       â”‚
â”‚  â€¢ TrawFormatter (TRAW, Parquet, CSV, JSON output)              â”‚
â”‚  â€¢ QC reports & harmonization statistics                        â”‚
â”‚  â€¢ Hardy-Weinberg equilibrium calculations                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CONFIGURATION & UTILITIES                     â”‚
â”‚  app/core/config.py â€¢ app/utils/parquet_io.py                   â”‚
â”‚  â€¢ Settings & optimization â€¢ app/utils/paths.py                 â”‚
â”‚  â€¢ Path management â€¢ app/models/ (data structures)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”„ Data Flow & Relationships

### **Main Processing Flow:**
1. **`run_carriers_pipeline.py`** â†’ Entry point
2. **`ExtractionCoordinator`** â†’ Orchestrates entire pipeline
3. **`VariantExtractor`** â†’ Extracts genotypes from PLINK files
4. **`HarmonizationEngine`** â†’ Harmonizes alleles between SNP list and PLINK files
5. **`GenotypeTransformer`** â†’ Applies genotype transformations
6. **`TrawFormatter`** â†’ Formats and exports results

### **Inter-Class Dependencies:**

```mermaid
graph TD
    A[ExtractionCoordinator] --> B[VariantExtractor]
    A --> C[GenotypeTransformer]
    A --> D[TrawFormatter]
    A --> E[Settings]
    
    B --> F[HarmonizationEngine]
    B --> C
    B --> E
    
    F --> G[HarmonizationRecord]
    F --> H[HarmonizationAction]
    
    D --> I[parquet_io]
    
    E --> J[PgenFileSet]
    
    A --> K[ExtractionPlan]
    K --> L[DataType]
```

## ðŸ“‹ Complete Class & Function Reference

### **Core Configuration (`app/core/`)**

#### **`Settings` Class** (config.py:7)
**Purpose**: Central configuration management with auto-optimization

**Key Methods:**
- `create_optimized()` â†’ Auto-detects machine specs and optimizes performance
- `get_optimal_workers(total_files)` â†’ Calculates optimal ProcessPool workers
- `get_nba_path(ancestry)` â†’ NBA file paths
- `get_wgs_path()` â†’ WGS file paths  
- `get_imputed_path(ancestry, chrom)` â†’ Imputed file paths
- `validate_file_paths()` â†’ Validates PLINK file existence
- `list_available_ancestries(data_type)` â†’ Available ancestry groups
- `list_available_chromosomes(ancestry)` â†’ Available chromosomes

**Performance Properties:**
- `max_workers` â†’ ProcessPool worker count
- `chunk_size` â†’ Processing chunk size
- `process_cap` â†’ Maximum concurrent processes

---

### **Processing Pipeline (`app/processing/`)**

#### **`ExtractionCoordinator` Class** (coordinator.py:96)
**Purpose**: Main orchestrator for the entire extraction pipeline

**Key Methods:**
- `run_full_extraction_pipeline()` â†’ **Main entry point** - runs complete pipeline
- `execute_harmonized_extraction()` â†’ Orchestrates ProcessPool parallel extraction
- `plan_extraction()` â†’ Creates extraction plan for multi-source processing
- `export_results_cache_free()` â†’ Exports results with real-time harmonization
- `load_snp_list()` â†’ Loads and validates SNP list
- `_execute_with_process_pool()` â†’ Manages ProcessPool execution

**Process Workers:**
- `extract_single_file_process_worker()` â†’ **ProcessPool worker function**
- `_parse_ancestry_from_path()` â†’ Helper for ancestry detection

#### **`VariantExtractor` Class** (extractor.py:29)
**Purpose**: Extracts variants from PLINK files with harmonization integration

**Key Methods:**
- `extract_single_file_harmonized()` â†’ **Main extraction method** - extracts with real-time harmonization
- `_extract_raw_genotypes()` â†’ Raw genotype extraction from PLINK files
- `_extract_with_plink2()` â†’ PLINK2 command execution with memory optimization
- `_harmonize_extracted_genotypes()` â†’ Applies harmonization to extracted genotypes
- `_check_plink_availability()` â†’ PLINK2 availability check
- `_simulate_plink_extraction()` â†’ Fallback simulation for testing

**Internal Helpers:**
- `_read_traw_file()` â†’ Reads PLINK TRAW format
- `_reconstruct_snp_list_from_ids()` â†’ SNP list reconstruction
- `_harmonization_records_to_plan_df()` â†’ Convert harmonization records to plan

#### **`HarmonizationEngine` Class** (harmonizer.py:15)
**Purpose**: Real-time allele harmonization using merge-based approach

**Key Methods:**
- `harmonize_variants()` â†’ **Main harmonization method** - harmonizes SNP list vs PVAR
- `read_pvar_file()` â†’ Reads PVAR files with VCF-style header support
- `_merge_data()` â†’ Merges PVAR and SNP list on chromosome/position
- `_harmonize_on_merged()` â†’ Direct allele comparison and action determination
- `_prepare_snp_list()` â†’ Normalizes SNP list for merging

**Harmonization Actions:**
- EXACT â†’ No transformation needed
- SWAP â†’ Allele swap (genotype: 2-x)
- FLIP â†’ Strand flip (no genotype transform)
- FLIP_SWAP â†’ Both strand flip and allele swap (genotype: 2-x)

#### **`GenotypeTransformer` Class** (transformer.py:18)
**Purpose**: Applies genotype transformations for allele harmonization

**Key Methods:**
- `apply_transformation_by_formula()` â†’ **Main transform method** - applies formula-based transformations
- `get_transformation_summary()` â†’ Statistics on transformations needed
- `transform_for_swap()` â†’ Allele swap transformation (0â†”2)
- `transform_for_flip()` â†’ Strand flip (no genotype change)
- `validate_transformation()` â†’ Validates transformation correctness
- `get_allele_counts()` â†’ Calculates allele frequencies
- `transform_matrix()` â†’ Batch transformation for multiple variants

**Transformation Formulas:**
- `"2-x"` â†’ Swap transformation (0â†’2, 1â†’1, 2â†’0)
- `"x"` or `None` â†’ Identity (no change)

#### **`TrawFormatter` Class** (output.py:23)
**Purpose**: Formats and exports harmonized results in multiple formats

**Key Methods:**
- `export_multiple_formats()` â†’ **Main export method** - exports TRAW, Parquet, CSV, JSON
- `write_traw()` â†’ PLINK TRAW format output
- `create_qc_report()` â†’ Quality control statistics
- `write_harmonization_report()` â†’ Harmonization process statistics
- `write_variant_summary()` â†’ Per-variant summary statistics
- `format_harmonized_genotypes()` â†’ Prepares data for output
- `_calculate_hwe_p()` â†’ Hardy-Weinberg equilibrium p-values

---

### **Data Models (`app/models/`)**

#### **Analysis Models** (analysis.py)
- `DataType` â†’ Enum: NBA, WGS, IMPUTED
- `AnalysisRequest` â†’ Request specification for variant analysis
- `AnalysisResult` â†’ Complete analysis results container

#### **Harmonization Models** (harmonization.py)
- `HarmonizationAction` â†’ Enum: EXACT, SWAP, FLIP, FLIP_SWAP, INVALID, AMBIGUOUS
- `HarmonizationRecord` â†’ Variant harmonization metadata
- `ExtractionPlan` â†’ Multi-source extraction planning
- `HarmonizationStats` â†’ Harmonization process statistics

#### **Carrier Models** (carrier.py)
- `GenotypeValue` â†’ Enum: Genotype values (0/0, 0/1, 1/1, ./.)
- `Genotype` â†’ Individual genotype record
- `Carrier` â†’ Extended genotype with clinical metadata
- `CarrierReport` â†’ Complete carrier analysis report

#### **Variant Models** (variant.py)
- `InheritancePattern` â†’ Enum: AD, AR, XL, MT
- `Variant` â†’ Genomic variant with coordinates
- `VariantList` â†’ Collection of variants with metadata

---

### **Utilities (`app/utils/`)**

#### **Path Management** (paths.py)
- `PgenFileSet` â†’ PLINK file validation and metadata
- `validate_pgen_files()` â†’ File existence validation

#### **Parquet I/O** (parquet_io.py)
- `save_parquet()` â†’ Optimized genomic data storage
- `read_parquet()` â†’ Efficient data loading with filtering
- `optimize_dtypes_for_genomics()` â†’ Memory optimization for genomic data

---

## ðŸ”§ **Key Design Patterns**

### **1. ProcessPool Parallelization**
- **Pattern**: True parallel processing using ProcessPoolExecutor
- **Implementation**: `coordinator.py:_execute_with_process_pool()`
- **Worker Function**: `extract_single_file_process_worker()` (module-level for serialization)
- **Benefits**: True concurrency, memory isolation, optimal resource usage

### **2. Real-Time Harmonization**
- **Pattern**: Merge-based harmonization without pre-processing
- **Implementation**: `harmonizer.py:HarmonizationEngine`
- **Flow**: PVAR + SNP list â†’ merge on chr:pos â†’ allele comparison â†’ action determination
- **Benefits**: No caching overhead, always up-to-date, memory efficient

### **3. Multi-Source Data Integration**
- **Pattern**: Unified extraction across NBA/WGS/IMPUTED with separate outputs
- **Implementation**: `coordinator.py:ExtractionCoordinator`
- **Benefits**: Consistent processing, separate data type outputs, comprehensive coverage

### **4. Memory-Efficient Processing**
- **Pattern**: Stream processing, chunk-based operations, optimal data types
- **Implementation**: Throughout pipeline, especially `parquet_io.py`
- **Benefits**: <8GB RAM usage, handles large datasets, fast processing

---

## ðŸ“Š **Performance Characteristics**

### **Processing Targets:**
- **Speed**: <10 minutes for 400 variants across all files
- **Memory**: <8GB RAM usage
- **Concurrency**: 10+ simultaneous jobs supported
- **Scalability**: Auto-optimization based on machine specs

### **Current System Optimization:**
- **CPU**: 32 cores â†’ 28 workers (auto-detected)
- **RAM**: 128GB â†’ 50K chunk_size
- **Files**: 242+ PLINK files processed in parallel
- **Output**: Separate datasets per data type (NBA/WGS/IMPUTED)

This architecture provides a robust, scalable, and maintainable system for genomic carrier screening with excellent performance characteristics and clear separation of concerns.