"""
Methods descriptions for precision medicine pipeline data generation.

Provides comprehensive but concise methodology text for display in the frontend,
explaining how each type of data is generated and analyzed.
"""


class MethodsDescriptions:
    """
    Centralized methods descriptions for pipeline data generation.

    Provides markdown-formatted methodology text for each analysis type,
    designed to be displayed in expandable UI sections.
    """

    @staticmethod
    def get_locus_reports_methods() -> str:
        """
        Get methods description for locus reports generation.

        Returns:
            Markdown-formatted methods text
        """
        return """
### Locus Reports Generation

**Overview:**
Per-gene clinical phenotype statistics are generated by integrating genotype data with clinical assessments,
stratified by genetic ancestry to identify population-specific carrier patterns.

**Data Sources:**
1. **Genotype Data**: Pathogenic variant carriers extracted from PLINK 2.0 files (NBA/WGS/IMPUTED)
2. **Master Key**: Sample metadata including genetic ancestry labels (`nba_label`)
3. **Extended Clinical Data**: Baseline visit (visit_month=0) clinical assessments

**Analysis Steps:**

1. **Carrier Identification**
   - Extract genotype calls for pathogenic variants from parquet files
   - Identify carriers: heterozygous (genotype=1) or homozygous (genotype=2)
   - Group variants by gene/locus based on SNP list annotations

2. **Ancestry Stratification**
   - Join genotype data with master key using sample IDs (GP2ID)
   - Assign genetic ancestry from `nba_label` field (AAC, AFR, AJ, AMR, CAH, CAS, EAS, EUR, FIN, MDE, SAS)
   - Calculate carrier frequencies per ancestry group

3. **Clinical Data Integration**
   - Filter extended clinical data to baseline visits only
   - Join carrier samples with clinical assessments using GP2ID
   - Extract key clinical metrics:
     - **H&Y Stage**: Hoehn and Yahr disease severity (0-5 scale)
     - **MoCA Score**: Montreal Cognitive Assessment (0-30 scale)
     - **DAT Imaging**: Dopamine transporter SBR caudate mean
     - **Disease Duration**: `age_at_sample_collection` − `age_of_onset` (both from master key)

4. **Statistics Calculation**
   - **Per-ancestry metrics**: Carrier counts, clinical data availability, phenotype distributions
   - **Aggregated metrics**: Total carriers across all ancestries, overall clinical characteristics
   - **Variant-level counts**: Heterozygous vs homozygous carrier frequencies per variant

**Output Metrics:**
- Total carriers identified (all ancestries)
- Carriers with available clinical data
- Clinical phenotype distributions (H&Y < 2, MoCA ≥ 24, disease duration ≤3/≤5/≤7 years)
- Ancestry-specific carrier frequencies
- Variant-level genotype counts (heterozygous/homozygous)

**Quality Control:**
- Only baseline visit data used (visit_month=0) to avoid duplicate measurements
- Clinical metrics filtered for valid/non-missing values
- Ancestry labels validated against master key reference
"""

    @staticmethod
    def get_probe_validation_methods() -> str:
        """
        Get methods description for probe validation analysis.

        Returns:
            Markdown-formatted methods text
        """
        return """
### Probe Validation Analysis

**Overview:**
When multiple NBA (NeuroBooster Array) probes target the same genomic position, probe quality is validated
against WGS (Whole Genome Sequencing) ground truth data using dual-metric analysis to identify the most
accurate probe for carrier screening.

**Data Sources:**
1. **NBA Data**: Genotyping array probes (may have multiple probes per genomic position)
2. **WGS Data**: Whole genome sequencing ground truth genotypes
3. **Shared Samples**: Individuals with both NBA and WGS data for direct comparison

**Analysis Steps:**

1. **Multiple Probe Detection**
   - Identify genomic positions with multiple NBA probes (different variant IDs, same chromosome/position)
   - Match NBA variants to corresponding WGS variants using SNP list annotations
   - Filter to mutations with 2+ probes for validation

2. **Sample Alignment**
   - Identify overlapping samples between NBA and WGS datasets
   - Normalize sample IDs for consistent matching
   - Extract genotype calls for comparison

3. **Diagnostic Classification Analysis**

   This approach treats the probe as a **binary classifier** for carrier status detection:

   - **Classification setup**:
     - Positive class: Carrier (WGS genotype > 0, i.e., heterozygous or homozygous for pathogenic allele)
     - Negative class: Non-carrier (WGS genotype = 0, i.e., no pathogenic allele)
     - Prediction: NBA probe genotype used to classify carrier vs non-carrier status

   - **Confusion matrix generation**:
     ```
                    WGS Truth
                 Carrier  Non-carrier
     NBA  Carrier    TP        FP
          Non-car.   FN        TN
     ```
     - **TP (True Positive)**: NBA detects carrier, WGS confirms carrier
     - **TN (True Negative)**: NBA detects non-carrier, WGS confirms non-carrier
     - **FP (False Positive)**: NBA detects carrier, but WGS shows non-carrier
     - **FN (False Negative)**: NBA misses carrier that WGS detects

   - **Metric calculations**:
     - **Sensitivity = TP / (TP + FN)**: Ability to correctly identify true carriers
       - High sensitivity = few missed carriers (low false negatives)
     - **Specificity = TN / (TN + FP)**: Ability to correctly identify non-carriers
       - High specificity = few false alarms (low false positives)
     - **Diagnostic Score = Sensitivity + Specificity**: Combined performance metric

   - **Clinical interpretation**:
     - Sensitivity prioritizes *not missing carriers* (critical for genetic screening)
     - Specificity prioritizes *avoiding false positives* (reduces unnecessary follow-up)
     - Optimal probe balances both metrics for accurate carrier detection

4. **Genotype Concordance Analysis**

   This approach evaluates **exact genotype agreement** across all three genotype states:

   - **Comparison setup**:
     - Genotype states: 0 (homozygous reference), 1 (heterozygous), 2 (homozygous alternate)
     - For each shared sample, compare NBA genotype to WGS genotype
     - Track exact matches and specific mismatch patterns

   - **Transition matrix generation**:
     ```
                      WGS Truth
                   0     1     2
     NBA      0   n00   n01   n02
              1   n10   n11   n12
              2   n20   n21   n22
     ```
     - Diagonal (n00, n11, n22): Concordant calls
     - Off-diagonal: Discordant calls showing specific error patterns
     - Example: n01 = NBA calls 0 when WGS shows 1 (missed heterozygote)

   - **Metric calculations**:
     - **Overall Concordance = (n00 + n11 + n22) / Total Samples**: Proportion of exact matches
     - **Per-genotype Concordance**: Accuracy for each genotype class
       - Genotype 0 accuracy: n00 / (n00 + n01 + n02)
       - Genotype 1 accuracy: n11 / (n10 + n11 + n12)
       - Genotype 2 accuracy: n22 / (n20 + n21 + n22)
     - **Quality Score = Concordance × Call Rate**: Penalizes probes with missing data

   - **Error pattern analysis**:
     - Identifies systematic biases (e.g., heterozygote undercalling: n10 > 0, n12 > 0)
     - Detects genotype compression (e.g., all calls as heterozygous)
     - Reveals probe-specific technical issues

5. **Consensus Recommendation**

   The final probe selection integrates both analytical approaches:

   - **Method 1: Diagnostic-based Selection**:
     - Rank probes by diagnostic score (sensitivity + specificity)
     - Select probe with highest combined score
     - Prioritizes clinical screening performance

   - **Method 2: Concordance-based Selection**:
     - Rank probes by quality score (concordance × call rate)
     - Select probe with highest quality score
     - Prioritizes overall genotyping accuracy

   - **Consensus Algorithm**:
     - Compare recommended probes from both methods
     - **Agreement**: If both methods select same probe → High confidence recommendation
     - **Disagreement**: Diagnostic method's choice is used as the default selection
     - Report agreement rate across all mutations

   - **Disagreement Resolution**:
     - When methods disagree, **diagnostic (sensitivity-based) selection wins**
     - Rationale: For clinical screening, missing a true carrier (false negative) has worse consequences than a false positive
     - A false positive leads to confirmatory testing; a false negative means a patient doesn't get appropriate monitoring
     - Disagreements are flagged in output with lowered confidence scores for manual review if needed

   - **Interpretation**:
     - High agreement rate (>90%): Methods are well-aligned, recommendations are robust
     - Low agreement: May indicate trade-offs between carrier detection vs genotyping accuracy
     - Disagreements typically occur when one probe has excellent carrier detection but poor dosage accuracy

**Output Metrics:**

*Diagnostic Metrics:*
- Sensitivity (true positive rate)
- Specificity (true negative rate)
- Positive/negative predictive values
- Confusion matrix

*Concordance Metrics:*
- Overall concordance rate
- Genotype transition matrix
- Quality score (concordance × call rate)
- Per-genotype concordance rates

*Recommendations:*
- Selected probe per mutation
- Confidence level (high/medium/low)
- Method agreement rate
- Disagreement analysis

**Quality Control:**
- Minimum sample overlap required for valid comparison
- Call rate thresholds for quality scoring
- Validation of allele harmonization before comparison
- Cross-method consistency checks
"""

    @staticmethod
    def get_genotype_extraction_methods() -> str:
        """
        Get methods description for genotype extraction pipeline.

        Returns:
            Markdown-formatted methods text
        """
        return """
### Genotype Extraction Pipeline

**Overview:**
Pathogenic variant genotypes are extracted from large-scale PLINK 2.0 files across multiple data types
(NBA/WGS/IMPUTED) with proper allele harmonization and normalization to ensure accurate carrier identification.

**Data Sources:**
1. **NBA Data**: NeuroBooster Array genotypes (11 ancestry-specific files)
2. **WGS Data**: Whole genome sequencing (1 consolidated file)
3. **IMPUTED Data**: Imputed genotypes (242 files: 11 ancestries × 22 chromosomes)
4. **SNP List**: Curated list of ~400 pathogenic variants with genomic coordinates

**Processing Steps:**

1. **Variant Extraction**
   - Use PLINK 2.0 to extract target variants from binary PGEN/PVAR/PSAM files
   - Process files in parallel using ProcessPool for multi-file datasets
   - Memory-efficient streaming for large files (>1M variants each)

2. **Allele Harmonization**
   - **Merge-based approach**: Direct comparison of PVAR file alleles with SNP list
   - **Harmonization actions**:
     - **EXACT**: Alleles match exactly, no transformation needed
     - **FLIP**: Strand flip (A↔T, C↔G)
     - **SWAP**: Ref/alt swap (count alt allele instead of ref)
     - **FLIP_SWAP**: Combined strand flip and ref/alt swap
   - Real-time validation of allele assignments

3. **Genotype Transformation**
   - **Critical correction**: Transform genotypes to count **pathogenic alleles** (not reference alleles)
   - Apply transformation formulas based on harmonization action:
     - EXACT/FLIP: genotype unchanged (already counts pathogenic allele)
     - SWAP/FLIP_SWAP: invert genotype (2 - genotype) to count alternate allele
   - Validate genotype values: 0 (no pathogenic alleles), 1 (heterozygous), 2 (homozygous)

4. **Sample ID Normalization**
   - Remove data type prefixes:
     - NBA/IMPUTED: `0_SAMPLE_001234` → `SAMPLE_001234`
     - WGS: `SAMPLE_001234_SAMPLE_001234` → `SAMPLE_001234`
   - Ensure consistent sample IDs across all data types
   - Enable cross-dataset analysis and merging

5. **Data Organization**
   - **Column order**: Metadata columns first, then alphabetically sorted sample columns
   - **Metadata**: chromosome, variant_id, position, counted_allele, alt_allele, harmonization_action
   - **Multi-ancestry merging**: Outer join to preserve all samples across ancestries

**Output Format:**
- **Parquet files**: Optimized columnar storage with compression
- **Variant summary**: Harmonization metadata per variant
- **Pipeline results**: Overall execution summary with sample/variant counts

**Quality Control:**
- Validation of harmonization actions before genotype transformation
- Sample ID consistency checks across data types
- Genotype value range validation (0-2 for discrete calls, 0.0-2.0 for dosages)
- Duplicate variant detection and resolution
- Call rate and missingness reporting

**Performance Optimizations:**
- ProcessPool parallelization for multi-file datasets
- Memory mapping for large file handling
- Chunk-based processing with auto-tuned chunk sizes
- Machine tier detection for optimal worker allocation
"""

    @staticmethod
    def get_pipeline_overview_methods() -> str:
        """
        Get general pipeline overview methods description.

        Returns:
            Markdown-formatted methods text
        """
        return """
### Precision Medicine Pipeline Overview

**Purpose:**
Identify carriers of pathogenic variants in large-scale genomic cohorts and integrate with clinical
phenotype data to enable genotype-phenotype association studies in Parkinson's disease.

**Pipeline Phases:**

1. **Genotype Extraction**
   - Extract pathogenic variants from PLINK 2.0 files across 3 data types
   - Harmonize alleles to ensure accurate pathogenic allele counting
   - Normalize sample IDs for cross-dataset integration

2. **Probe Validation** (if multiple probes exist)
   - Validate NBA probe quality against WGS ground truth
   - Select optimal probes for carrier screening accuracy

3. **Locus Reports Generation**
   - Integrate genotype data with clinical assessments
   - Stratify by genetic ancestry for population-specific analysis
   - Calculate carrier frequencies and clinical phenotype distributions

**Data Integration:**
- **Genomic**: ~400 pathogenic SNPs across 242+ PLINK files (>1M variants each)
- **Clinical**: Baseline visit assessments (H&Y, MoCA, DAT imaging, disease duration)
- **Ancestry**: Genetic ancestry labels from principal component analysis

**Key Features:**
- Correct pathogenic allele counting with proper genotype transformation
- Multi-ancestry support (11 ancestry groups)
- Cross-dataset sample matching and normalization
- Ancestry-stratified clinical statistics
- Evidence-based probe selection for optimal accuracy

**Output Files:**
- Genotype matrices (parquet format)
- Locus clinical reports (JSON/CSV)
- Probe validation reports (JSON)
- Pipeline execution summaries (JSON)

**Quality Assurance:**
- Allele harmonization validation
- Sample ID consistency checks
- Clinical data baseline filtering
- Probe quality metrics
- Cross-method validation
"""

    @staticmethod
    def get_coverage_reports_methods() -> str:
        """
        Get methods description for coverage reports.

        Returns:
            Markdown-formatted methods text
        """
        return """
### Coverage Profiling Analysis

**Overview:**
Coverage profiling analyzes which variants from the SNP list actually exist in each data type's
source files (pvar files). This helps identify data availability issues before interpreting
extraction results - variants cannot be extracted if they don't exist in the source data.

**Data Sources:**
1. **SNP List**: Curated list of pathogenic variants with hg38 coordinates (chr:pos:ref:alt)
2. **Source pvar Files**: Variant metadata files for each data type:
   - WGS: Per-chromosome, per-ancestry files
   - IMPUTED: Per-chromosome, per-ancestry files
   - NBA: Single file per ancestry (raw genotypes)
   - EXOMES: Per-chromosome files

**Analysis Steps:**

1. **SNP List Normalization**
   - Load pathogenic variant list with hg38 coordinates
   - Normalize chromosome format (ensure 'chr' prefix)
   - Create variant_id (chr:pos:ref:alt) and position key (chr:pos)

2. **Source File Scanning**
   - Scan pvar files for each data type (using EUR ancestry as reference)
   - Extract variant positions and alleles from source files
   - Process files in parallel for efficiency

3. **Match Detection**

   **Exact Matching:**
   - Compare full variant ID: chr:pos:ref:alt
   - Requires chromosome, position, AND alleles to match exactly
   - Represents variants that can be extracted without harmonization issues

   **Position Matching:**
   - Compare position only: chr:pos
   - Finds variants at same genomic position regardless of allele representation
   - Indicates potential matches that may need allele harmonization
   - Useful for detecting strand flips or indel normalization differences

4. **Coverage Aggregation**
   - **By Locus**: Sum exact/position matches per gene/locus
   - **By Variant**: Boolean flags for presence in each data type
   - **By Data Type**: Overall coverage percentage

**Interpreting Results:**

| Match Type | Meaning |
|------------|---------|
| Exact Match | Variant exists with same alleles - ready for extraction |
| Position Match Only | Position exists but alleles differ - may need harmonization |
| No Match | Variant not present in source data - cannot be extracted |

**Why Coverage Varies by Data Type:**

- **WGS**: Contains all variants detected by sequencing, best for rare variants
- **IMPUTED**: Limited to variants that can be accurately imputed from array data
- **NBA**: Contains only variants on the NeuroBooster Array design
- **EXOMES**: Contains only coding region variants

**Output Files:**
- `coverage_by_locus.csv`: Per-gene coverage statistics
- `coverage_by_variant.csv`: Per-variant presence flags
- `coverage_summary.json`: Overall statistics

**Performance:**
- Parallelized scanning across chromosomes and data types
- Uses only pvar metadata files (not full genotype data)
- Typical runtime: ~5 minutes on 32-core machine
"""

    @classmethod
    def get_all_methods(cls) -> dict:
        """
        Get all methods descriptions as a dictionary.

        Returns:
            Dictionary mapping method names to description text
        """
        return {
            'locus_reports': cls.get_locus_reports_methods(),
            'probe_validation': cls.get_probe_validation_methods(),
            'genotype_extraction': cls.get_genotype_extraction_methods(),
            'pipeline_overview': cls.get_pipeline_overview_methods(),
            'coverage_reports': cls.get_coverage_reports_methods()
        }
